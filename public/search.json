[{"title":"N1安装CoreELEC并安装Docker、Zerotier","url":"/shmily-blog/2020/03/03/coreelec/","content":"\nN1安装CoreELEC并安装Docker、Zerotier， 并设置Zerotier开机自启\n\n## 安装CoreELEC\n\n[传送门](https://www.right.com.cn/forum/thread-1135262-1-1.html)\n\n## 安装Docker\n\n直接再CoreELEC的插件库 服务插件中安装即可\n\n### 使用 Portainer 工具管理 Docker\n\n在开发环境下使用此方式合适， 生产环境**不建议**\n\n1. 开启docker api\n2. 设置docker镜像源为国内源，（提高下载镜像的速度）\n\n修改启动文件\n\n`vi /storage/.kodi/addons/service.system.docker/system.d/service.system.docker.service`\n\n```sh\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network.target\n\n[Service]\nType=notify\nEnvironment=PATH=/bin:/sbin:/usr/bin:/usr/sbin:/storage/.kodi/addons/service.sys                                      tem.docker/bin\nExecStartPre=/storage/.kodi/addons/service.system.docker/bin/docker-config\nEnvironmentFile=-/storage/.kodi/userdata/addon_data/service.system.docker/config                                      /docker.conf\nExecStart=/storage/.kodi/addons/service.system.docker/bin/dockerd -H tcp://0.0.0                                      .0:2375 -H unix:///var/run/docker.sock --registry-mirror=https://el2yu6j2.mirror                                      .aliyuncs.com --exec-opt native.cgroupdriver=systemd --log-driver=journald --gro                                      up=root $DOCKER_DAEMON_OPTS $DOCKER_STORAGE_OPTS\nExecReload=/bin/kill -s HUP $MAINPID\nTasksMax=8192\nLimitNOFILE=1048576\nLimitNPROC=1048576\nLimitCORE=infinity\nTimeoutStartSec=0\nRestart=on-abnormal\n\n[Install]\nWantedBy=multi-user.target\nAlias=docker.service\n```\n\n**注意 ExecStart 这个参数，我遇到的坑，就是这行命令不能换行**\n\n加上 `-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --registry-mirror=https://el2yu6j2.mirror.aliyuncs.com`\n\n重新启动\n\n```sh\n$ systemctl daemon-reload\n$ systemctl restart docker\n```\n\n测试\n\n```sh\n$ netstat -anp |grep 2375\n```\n\n查看docker是否监听 2375 端口\n\n![ ](./0.png)\n\n## 安装Zerotier\n\n### 安装 ent\n\n### zerotier 开机自启动\n\nzerotier的服务启动文件 `zerotier-one.service`, 放在 `/storage/.config/system.d/` 下面\n\n```sh\n[Unit]\nDescription=zerotier-one                             # 服务名称，不重复就🆗\nAfter=syslog.target network.target\n\n[Service]\nType=forking\nPIDFile=/opt/var/lib/zerotier-one/zerotier-one.pid   # 这里按照你的软件安装目录而定\nExecStart=/opt/bin/zerotier-one -d                   # 这里按照你的软件安装目录而定\nExecReload=/bin/kill -s HUP $MAINPID\nExecStop=/bin/kill -s QUIT $MAINPID\nPrivateTmp=true\nUser=root\nGroup=root\n\n[Install]\nWantedBy=multi-user.target\n```\n\n执行命名：\n\n```sh\n$ systemctl daemon-reload\n$ systemctl restart zerotier-one\n$ systemctl enable zerotier-one\n```\n\n## 其他\n","tags":["coreelec N1"]},{"title":"StreamSets","url":"/shmily-blog/2020/02/03/streamsets/","content":"\nStreamSets 是我在迁移mysql数据到clickhouse中发现的, 现在来总结一下\n\nStreamsets是一款大数据实时采集和ETL工具，可以实现不写一行代码完成数据的采集和流转。通过拖拽式的可视化界面，实现数据管道(Pipelines)的设计和定时任务调度。最大的特点有：\n\n- 可视化界面操作，不写代码完成数据的采集和流转\n- 内置监控，可是实时查看数据流传输的基本信息和数据的质量\n- 强大的整合力，对现有常用组件全力支持，包括50种数据源、44种数据操作、46种目的地。\n\n对于Streamsets来说，最重要的概念就是数据源(Origins)、操作(Processors)、目的地(Destinations)。创建一个Pipelines管道配置也基本是这三个方面。\n\n常见的Origins有Kafka、HTTP、UDP、JDBC、HDFS等；Processors可以实现对每个字段的过滤、更改、编码、聚合等操作；Destinations跟Origins差不多，可以写入Kafka、Flume、JDBC、HDFS、Redis等。\n\n## 使用docker创建 StreamSets 实例\n\n```sh\ndocker run --rm -v /Users/aolei/app/streamsets/sdc-data:/data:rw -v /Users/aolei/app/streamsets/sdc-libs/jdbc:/opt/streamsets-datacollector-3.13.0/streamsets-libs-extras/streamsets-datacollector-jdbc-lib/lib/:rw -p 18630:18630 -d streamsets/datacollector dc\n```\n\n## 使用官方核心包运行\n\n[官网](https://streamsets.com/)\n\n[官网下载地址直达](https://streamsets.com/products/dataops-platform/open-source/)\n\n> 下载之前需要填写一些简单的信息\n\n### 配置很简单\n\n保存streamsets的配置 `-v /Users/aolei/app/streamsets/sdc-data:/data:rw`\n\n使用本地的 libs `-v /Users/aolei/app/streamsets/sdc-libs/lib:/opt/ streamsets-datacollector-3.13.0/streamsets-libs/:rw`\n\n## StreamSets 迁移 mysql - clickhouse 使用\n\n### 准备所需的jdbc jar包\n\n如果本地有 maven 环境的, 可以创建一个 `pom.xml` 文件\n\n```xml\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>com.anjia</groupId>\n  <artifactId>demo</artifactId>\n  <packaging>jar</packaging>\n  <version>1.0-SNAPSHOT</version>\n  <name>demo</name>\n  <url>http://maven.apache.org</url>\n  <dependencies>\n    <dependency>\n        <groupId>ru.yandex.clickhouse</groupId>\n        <artifactId>clickhouse-jdbc</artifactId>\n        <version>0.1.54</version>\n    </dependency>\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>5.1.47</version>\n  </dependency>\n  </dependencies>\n</project>\n```\n\n执行 `mvn dependency:copy-dependencies -DoutputDirectory=lib -DincludeScope=compile` 会在当前目录下生成**lib**文件夹,复制其中的jar包到`/Users/aolei/app/streamsets/sdc-libs/lib`(*你本地映射的streamsets lib目录*)\n\n## 总结\n\n[本文借鉴-简书 北邮郭大宝](https://www.jianshu.com/p/870e1bb52da4)\n","tags":["大数据"]},{"title":"Windows10下的子系统Linux","url":"/shmily-blog/2020/01/08/msl/","content":"\nWindows10出了一款子系统Linux,可以方便开发者不在需要依赖虚拟机啦\n\n## 开始\n\n首先你得是windows10最新版本的系统\n\n进入 系统设置 -> 更新和安全 -> 开发者选项 打开\n\n![ ](./WX20200108-154615@2x.png)\n\n![ ](./WX20200108-154856@2x.png)\n\n其次是 进入 控制面板-程序和功能-启用或关闭Windows功能下 选择 “适用于Linux的Window之系统”\n\n![ ](./WX20200108-155336@2x.png)\n\n然后**重启系统**\n\n## 安装Linux系统\n\n打开Windows10的应用商店, 搜索Linux会得到以下结果, 点击第一个进入\n\n![ ](./A84A183D1145E8245B6A7C8A84FB985F.jpg)\n\n![ ](./WX20200108-155928@2x.png)\n\n这里我安装的是第一个 Ubuntu 系统\n\n![ ](./WX20200108-160028@2x.png)\n\n点击安装, 等待安装完成\n\n## 进入Linux系统\n\n安装完成之后, `Ctrl + R`打开CMD, 输入 `bash` 就会进入Linux系统了\n\n根据提示, 设置用户名、密码就好了\n\n![ ](./20180912154639866.png)\n\n## 子系统Ubuntu进阶(可选)\n\n### 更换 apt-get 安装源(可选、觉得网速好的可以不换)\n\n一般新安装的Linux系统都需要更新软件仓库的, 但是Ubuntu的默认仓库源是国外的,更新数据比较慢, 我们可以先更换软件仓库源为国内的(个人一般喜欢用*阿里*的源)\n\n#### 准备源\n\n查看系统版本\n\n```sh\nlsb_release -a\n```\n\n![ ](./WX20200108-164517@2x.png)\n\n> Codename 是你的系统版本代号\n> Ubuntu 12.04 (LTS)代号为precise。\n> Ubuntu 14.04 (LTS)代号为trusty。\n> Ubuntu 15.04 代号为vivid。\n> Ubuntu 15.10 代号为wily。\n> Ubuntu 16.04 (LTS)代号为xenial。\n> Ubuntu 18.04 (LTS)代号为bionic\n\nUbuntu 18.04 (LTS)代号为bionic 对应阿里云镜像仓库的地址为:\n\n```txt\ndeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\n\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\n```\n\n[这里最后面说明了,为什么要关注这个系统的版本号](https://blog.csdn.net/zhangjiahao14/article/details/80554616)\n\n### 修改 `/etc/apt/sources.list` 文件\n\n我们需要修改 `/etc/apt/sources.list` 文件\n\n第一步: 备份 `/etc/apt/sources.list` 文件\n\n```sh\nsudo cp /etc/apt/sources.list /etc/apt/sources.list.bak\n```\n\n> .bak 后缀的文件是linux系统中的备份文件\n\n第二部: 修改 `/etc/apt/sources.list` 文件\n\n```sh\nsudo vim /etc/apt/sources.list\n```\n\n![ ](./WX20200108-163130@2x.png)\n\n打开之后是这样的\n\n注释已有的源, 粘贴阿里的镜像地址保存即可\n\nvim编辑器说明:\n\nvi编辑器一共有三种模式，分别是命令模式（command mode）*默认*、插入模式（Insert mode）和底行模式（last line mode）。命令模式下我们只能控制屏幕光标的移动，字符、字或行的删除，移动复制某区段及进入Insert mode下，或者到 last line mode等；插入模式下可以做文字输入，按「ESC」键可回到命令行模式；底行模式下，可以将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号等。\n\nvim编辑器的常用命令:\n\n1. `vim /etc/apt/sources.list` 打开文件(不存在的文件,在保存时自动创建) 默认(命令模式)\n2. `i` (插入模式) 在光标前开始插入\n3. `a` (插入模式) 在光标后开始插入\n4. `shift + :` (命令模式) 调出vim的命令行, 输入命令(`wq`保存退出、`q!`不保存退出、 `w`仅保存)\n5. `d + up键` (命令模式) *浏览模式下* 删除一行\n\n#### apt-get update、 apt-get upgrade 不要忘记了, 不管有没有换源都要执行的\n\n### zsh\n\n*zsh*是一个终端shell程序,比默认的bash终端好用, 可以搭配*oh-my-zsh*美化你的命令行\n\n官网[oh-my-zsh](https://ohmyz.sh/)\n\n#### 安装 zsh oh-my-zsh\n\n安装zsh\n\n`sudo apt-get install zsh`\n\n检查zsh\n\n`zsh --version`\n\n如果没有看到版本号、或者报错,则说明安装失败了\n\n设置为默认终端\n\n`sudo chsh -s /usr/bin/zsh <username>`\n\n如果报错, 则看一下 `/etc/shells` 文件中是否包含 `/bin/zsh`、`/usr/bin/zsh`, 没有就添加\n\n![ ](./WX20200108-173249@2x.png)\n\n顺序不重要\n\n再次执行 `sudo chsh -s /usr/bin/zsh <username>`\n\n成功则**关闭终端,重新打开(退出用户,重新登陆)**\n\n执行 `bash` 进入Linux子系统\n\n执行 `echo $SHELL` 会输出 `/bin/zsh`\n\n执行 `$SHELL --version` 会输出 `zsh 5.4.2 (x86_64-ubuntu-linux-gnu)`\n\n上面两部执行正确,则说明安装zsh并设置为默认终端成功了,\n\n#### 我遇到的windows10子系统的一个问题\n\n在设置为默认终端时,为参考官方教程来做,无法将zsh设置为默认终端\n\n官方命令: `sudo chsh -s $(which zsh)`\n\n检查是否设置默认成功: `echo $SHELL`\n\n终端应该输出: `/bin/zsh`, 如果不是 或者是 空 则说明默认配置是失败的\n\n查看 `/etc/passwd` 文件中 对应你的用户配置 是否是 指定 `/bin/zsh`\n\n##### 最终解决问题的办法\n\n编辑 `~/.bash_profile` 文件，（不存在就创建）\n\n加入以下类容：\n\n```sh\n# 指定 zsh的目录\nexport SHELL=/bin/zsh\nexport PATH=$SHELL:$PATH\n\n# 每次打开终端的时候运行zsh\nexec $SHELL\n```\n\n![ ](./WX20200108-173321@2x.png)\n\n执行 `sudo chsh -s /usr/bin/zsh <username>` 命令 (最后面对应你的用户名)\n\n#### 下载 oh-my-zsh 美化zsh\n\n参考官方的教程\n\n使用 curl\n\n```sh\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n使用 wget\n\n```sh\nsh -c \"$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\"\n```\n\n默认是 robbyrussell 样式\n\n修改 `~/.zshrc` 的 `ZSH_THEME=robbyrussell` 值 即可更换样式, 如果你不想要任何样式,则将值设置为\"\"即可\n\n[主题库](https://github.com/ohmyzsh/ohmyzsh/wiki/Themes)\n\n### 其他\n\n后面需要学习的:\n\n1. 安装docker\n2. putty远程连接\n\n## 结束\n\n...\n","tags":["Windows"]},{"title":"梅林安装zerotier","url":"/shmily-blog/2020/01/02/meilin-zerotier/","content":"\n网件R7000刷梅林, 安装zerotier内网穿透工具, 并配置开机自启\n\n[参考](http://koolshare.cn/forum.php?mod=viewthread&tid=134930&extra=&ordertype=1)\n\n## 安装 entware\n\n```sh\nrm -rf /opt\n\nmkdir /opt\n\ncd /opt\n\nwget -O - http://qnapware.zyxmon.org/binaries-armv7/installer/entware_install_arm.sh | sh\n```\n\n> 然后会提示你选择哪个分区，选择你挂载的U盘分区\n\n```sh\n···省略\nInfo:  Looking for available partitions...\n[1] --> /tmp/mnt/sda1\n=>  Please enter partition number or 0 to exit\n[0-1]: 1 # 选1回车\n···省略\n```\n\n> 跑完之后只要不提示错误，就是安装成功了\n\n### 配置entware环境变量\n\n`vim /etc/profile`\n\n直接在前面/usr/sbin:这行下直接添加下面两行并保存退出（ESC+:wq+Enter）\n\n`/opt/bin:/opt/sbin:`\n\n使配置生效\n\n`source /etc/profile`\n\n### 检查entware环境安装情况看是否报错\n\n```sh\nopkg update\n\nopkg list\n```\n\n## 安装 zerotier\n\n```sh\nopkg update\n\nopkg install zerotier\n```\n\n## 启动zerotier服务\n\n## 添加端口映射表\n\n## 重启zerotier服务\n\n## 注意事项\n\n1. 安装zerotier之前先安装 entware, 这样才能安装最新版本的zerotier\n\n## 最后\n\n......\n","tags":["路由器"]},{"title":"mysql的explain命令","url":"/shmily-blog/2020/01/02/mysql-explain/","content":"\n**explain**关键字可以模拟MySQL优化器执行SQL语句，可以很好的分析SQL语句或表结构的性能瓶颈.\n\n## explain的用途\n\n1. 表的读取顺序如何\n2. 数据读取操作有哪些操作类型\n3. 哪些索引可以使用\n4. 哪些索引被实际使用\n5. 表之间是如何引用\n6. 每张表有多少行被优化器查询\n7. ......\n\n## explain的主要字段有\n\n1. **id** select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序\n2. **select_type** 查询类型\n3. **table** 正在访问哪个表\n4. **partitions** 匹配的分区\n5. **type** 访问的类型\n6. **possible_keys** 显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到\n7. **key** 实际使用到的索引，如果为NULL，则没有使用索引\n8. **key_len** 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度\n9. **ref** 显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值\n10. **rows** 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数\n11. **filtered** 查询的表行占表的百分比\n12. **Extra** 包含不适合在其它列中显示但十分重要的额外信息\n\n## 最后\n\n![ ](./2864885534-202c0878c1abf896.png)\n\n......\n","tags":["数据库"]},{"title":"小钢炮安装zerotier实现内网穿透","url":"/shmily-blog/2020/01/02/xgp-zerotier/","content":"\n小钢炮安装zerotier实现内网穿透\n\n## 安装zerotier\n\n### 一、安装 entware\n\n为了安装最新版本的zerotier,我们需要先安装 *entware*\n\n执行\n\n```sh\nrm -rf /opt\n\nmkdir /opt\n\ncd /opt\n\nwget -O - http://bin.entware.net/aarch64-k3.10/installer/alternative.sh | sh\n```\n\n将自带opkg改名为opkg_bak暂时停用 灯大固件更新可以改回来免重装系统更新软件\n\nmv /usr/bin/opkg /usr/bin/opkg_bak\n\n### 二、配置entware环境变量\n\n`vim /etc/profile`\n\n直接在前面/usr/sbin:这行下直接添加下面两行并保存退出（ESC+:wq+Enter）\n\n`/opt/bin:/opt/sbin:`\n\n使配置生效\n\n`source /etc/profile`\n\n### 三、检查entware环境安装情况看是否报错\n\n```sh\nopkg update\n\nopkg list\n```\n\n### 四、安装zerotier\n\n`opkg install zerotier`\n\n启动zerotier\n\n`zerotier-one -d`\n\n查看服务状态\n\n`zerotier-one info`\n\n## 加入已有zerotier网络\n\n1. 登陆并打开你的zerotier网络管理页面\n2. 拷贝你的网络ID\n\n![ ](./CD65E8E75C1CBF3BF60AFBF278909ACD.jpg)\n\n加入网络 `zerotier-cli join <netowkr-id>`\n\n查看网络状态 `zerotier-cli listnetworks`\n\n## 设置开机自启\n\n创建 /etc/init.d/S60zerotier-one.sh 文件\n\n编辑为以下内容\n\n```sh\n\n#! /bin/sh\n\ncase \"$1\" in\n  start)\n    if ( pidof zerotier-one )\n    then echo \"ZeroTier-One is already running.\"\n    else\n        echo \"Starting ZeroTier-One\" ;\n        /opt/bin/zerotier-one -d ;\n        echo \"$(date) Started ZeroTier-One\" >> /opt/var/log/zerotier-one.log ;\n    fi\n    ;;\n  stop)\n    if ( pidof zerotier-one )\n    then\n        echo \"Stopping ZeroTier-One\";\n        killall zerotier-one\n        echo \"$(date) Stopped ZeroTier-One\" >> /opt/var/log/zerotier-one.log\n    else\n        echo \"ZeroTier-One was not running\" ;\n    fi\n    ;;\n  status)\n    if ( pidof zerotier-one )\n    then echo \"ZeroTier-One is running.\"\n    else echo \"ZeroTier-One is NOT running\"\n    fi\n    ;;\n  *)\n    echo \"Usage: /etc/init.d/zerotier-one {start|stop|status}\"\n    exit 1\n    ;;\nesac\n\nexit 0\n\n```\n\n**授予权限**\n\n`chmod 777 /etc/init.d/S60zerotier-one.sh`\n\n## 结束\n\n完成以上操作即可在小钢炮中安装zerotier并实现开机自启\n","tags":["小钢炮"]},{"title":"GraphQL 学习","url":"/shmily-blog/2019/10/22/graphql/","content":"\nGraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时。 GraphQL 对你的 API 中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让 API 更容易地随着时间推移而演进，还能用于构建强大的开发者工具。\n\n[官网文档](https://www.apollographql.com/docs/apollo-server)\n\n## 入门\n\n这里使用 nodejs 来创建demo, 使用到的npm包如下:\n\n1. fastify\n2. apollo-server-fastify\n\n### 定义GraphQL 模型\n\n```typescript\nimport { gql } from 'apollo-server-core';\n\nconst typeDefs = gql`\n    # 自定义 类型\n    scalar Date\n\n    # 自定义一个模型\n    type Book {\n        title: String\n        author: String\n        sex: String\n    }\n    ...\n\n    # 定义输入模型\n    input BookForm {\n        title: String!\n        author: String!\n        sex: String!\n    }\n\n    # Query 定义查询的方法\n    type Query {\n        # 查询所以 books 的方法\n        getBooks: [Book]\n    }\n\n    # Mutation 定义更新的方法\n    type Mutation {\n        addBook(book: BookForm): Boolean\n    }\n`\n```\n\n1. 自定义类型用 `scalar` 标注\n2. 自定义模型用 `type` 标注\n3. 输入模型用 `input` 标注 (与模型的唯一区别是 关键字不同)\n\n> Query 和 Mutation 是GraphQL内的两个特殊模型, 我们在这里定义 *查询* 和 *更新* 及返回类型, typeDefs中只能各存在一个.\n\n### 定义GraphQL的 resolver\n\n```typescript\n    const resolvers = {\n        Query: {\n            // Query中实现typeDefs中定义的查询\n            getBooks: (obj: any, args: any, context: any, info: any) => {\n                return [];\n            }\n        },\n        Mutation: {\n            // Mutation中实现typeDefs中定义的更新\n            addBook: (obj: any, args: any, context: any, info: any) => {\n                console.log('----> params', args['book'])\n                return true;\n            }\n        },\n        // 实现typeDefs中自定义的模型\n        Book: {\n            // 针对 单个属性定义\n            sex: (book:any, args: any, context: any, info: any) => {\n                return book.sex === 1 ? '男' : '女';\n            }\n        }\n        // ... 多个自定义模型\n    }\n```\n\n> 注意: resolver 中 Query和Mutation 只能有一个\n\n### 开始使用\n\n```typescript\nimport { ApolloServer } from 'apollo-server-fastify';\nimport * as fastify from 'fastify';\n\nconst gqlserver =  new ApolloServer({\n    typeDefs,\n    resolvers\n})\n\nfast.register(gqlserver.createHandler());\n\nfast.listen(3000, '0.0.0.0', async (err, address) => {\n    if (err) {\n        fast.log.error(err, address);\n    } else {\n        console.info(`service start success > ${address}`);\n    }\n})\n```\n\n## 参考链接\n\n[](http://www.zhaiqianfeng.com/2017/06/learn-graphql-first-demo.html)\n\n[](http://www.zhaiqianfeng.com/2017/06/learn-graphql-type-system.html)\n\n[](http://www.zhaiqianfeng.com/2017/06/learn-graphql-action-by-javascript.html)\n","tags":["API"]},{"title":"clickhouse学习笔记","url":"/shmily-blog/2019/10/11/clickhouse/","content":"\nClickHouse是一个用于联机分析(**OLAP**)的**列式**数据库管理系统(DBMS)。\n\n## Clickhouse使用\n\n[官网](https://clickhouse.yandex/)\n\n[官方文档](https://clickhouse.yandex/docs/zh/)\n\n### 入门(单机)\n\n使用docker部署\n\n```sh\ndocker pull yandex/clickhouse-server:latest\ndocker run -d -p 8123:8123 -p 9000:9000 -p 9009:9009 --name clickhouse yandex/clickhouse-server:latest\n```\n\n> 其他方式安装参考 [部署运行](https://clickhouse.yandex/docs/zh/getting_started/)\n\n1. 默认没有用户, 设置用户名密码参考 `/etc/clickhouse-server/users.xml` 做添加/修改\n2. 默认数据库 `default`\n3. 自定义配置文件可以存放在 `/etc/clickhouse-server/config.d` 和 `/etc/clickhouse-server/users.d` 分别对应 系统配置/用户配置, 自动融合到主配置文件中\n\n### 集群\n\n#### 多副本\n\n在 `/etc/clickhouse-server/config.d` 下添加配置文件 `remote_servers.xml`, 例:\n\n```xml\n<yandex>\n    <remote_servers incl=\"clickhouse_remote_servers\" > <!--集群节点配置-->\n        <test_clu> <!-- 集群名称 -->\n            <shard> <!-- 分片1 -->\n                <internal_replication>false</internal_replication> <!-- 插入数据时,向所有副本插入数据 -->\n                <replica> <!-- 副本1 -->\n                    <default_database>default</default_database>\n                    <host>${host_name}</host> <!--ip-->\n                    <port>9000</port>  <!--port-->\n                    <user>default</user> <!-- 用户名密码.可选 -->\n                    <password>123456</password>\n                </replica>\n                <replica> <!-- 副本1 -->\n                    <default_database>default</default_database>\n                    <host>${host_name}</host>\n                    <port>9000</port>\n                    <user>default</user>\n                    <password>123456</password>\n                </replica>\n             </shard>\n         </test_clu>\n    </remote_servers>\n</yandex>\n```\n\n#### 分布式+多副本+高可用 (同步插入)\n\n1. 在 `/etc/clickhouse-server/config.d` 下添加配置文件 `remote_servers.xml`\n2. 在 `/etc/clickhouse-server/config.d` 下添加配置文件 `zookeeper.xml`\n3. 所有机器都需要创建相同的 `副本表、分布式表`\n4. zookeeper 用与分布式协调\n5. 分片参数 `internal_replication` 必须设置为 true\n6. marcos.xml **每个副本都应该唯一**\n\nsql参考\n\n```sql\n--  创建副本表\ncreate table if not exists default.c_user (\n    `id` int,\n    `name` Nullable(String),\n    `sex` int,\n    `address` Nullable(String),\n    `datetime` Date DEFAULT now()\n) ENGINE =MergeTree();\n\n-- 创建分布式表\ncreate table if not exists default.user_all (\n    `id` int,\n    `name` Nullable(String),\n    `sex` int,\n    `address` Nullable(String),\n    `datetime` Date DEFAULT now()\n) engine = Distributed(test_clu, 'default', 'c_user', rand()); -- 集群名称, 数据库, 副本表, 集群数据分配策略\n```\n\n`remote_servers.xml` 参考配置\n\n```xml\n<yandex>\n    <remote_servers incl=\"clickhouse_remote_servers\" >\n        <test_clu> <!-- 集群名称 -->\n            <shard> <!-- 分片1 -->\n                <internal_replication>true</internal_replication> <!-- 插入数据时,向所有副本插入数据 -->\n                <replica> <!-- 副本1 -->\n                    <default_database>default</default_database>\n                    <host>clickhouse_s1</host>\n                    <port>9000</port>\n                    <user>default</user>\n                    <password>123456</password>\n                </replica>\n                <replica> <!-- 副本2 -->\n                    <default_database>default</default_database>\n                    <host>clickhouse_s3</host>\n                    <port>9000</port>\n                    <user>default</user>\n                    <password>123456</password>\n                </replica>\n             </shard>\n             <shard> <!-- 分片2 -->\n                <internal_replication>true</internal_replication>\n                <replica> <!-- 副本1 -->\n                    <default_database>default</default_database>\n                    <host>clickhouse_s2</host>\n                    <port>9000</port>\n                    <user>default</user>\n                    <password>123456</password>\n                </replica>\n                <replica> <!-- 副本2 -->\n                    <default_database>default</default_database>\n                    <host>clickhouse_s4</host>\n                    <port>9000</port>\n                    <user>default</user>\n                    <password>123456</password>\n                </replica>\n             </shard>\n         </test_clu>\n    </remote_servers>\n\n    <!-- 数据压缩算法 -->\n    <clickhouse_compression>\n        <case>\n            <min_part_size>10000000000</min_part_size>\n            <min_part_size_ratio>0.01</min_part_size_ratio>\n            <method>lz4</method>\n        </case>\n    </clickhouse_compression>\n</yandex>\n```\n\n`zookeeper.xml` 参考配置\n\n```xml\n<yandex>\n    <zookeeper incl=\"zookeeper-servers\">\n        <node index=\"1\">\n            <host>clickhouse_zk0</host>\n            <port>2181</port>\n        </node>\n        <!-- 多节点配置\n        <node index=\"2\">\n            <host>clickhouse_zk1</host>\n            <port>2181</port>\n        </node>\n        -->\n    </zookeeper>\n</yandex>\n```\n\n#### 分布式+多副本+高可用 (复制表)\n\n上面的基础上再在 `/etc/clickhouse-server/config.d` 下添加配置文件 `macros.xml`\n\n这个方式与上面*同步插入*的区别是 *插入数据时,只向一个副本插入,其他副本自动复制数据*, 我们需要将表引擎由`MergeTree`改为`ReplicatedMergeTree`\n\n参考sql\n\n```sql\n--  创建副本表\ncreate table if not exists default.c_user (\n    `id` int,\n    `name` Nullable(String),\n    `sex` int,\n    `address` Nullable(String),\n    `datetime` Date DEFAULT now()\n) ENGINE =ReplicatedMergeTree('/clickhouse/tables/{shard}/default/c_user', '{replica}',`datetime` ,(`datetime`,`id`),8192);\n-- {shard} 会自动从 macros.xml 中获取配置\n-- {replica} 会自动从 macros.xml 中获取配置\n-- `datetime` 是时间类型的字段\n\n-- 创建分布式表\ncreate table if not exists default.user_all (\n    `id` int,\n    `name` Nullable(String),\n    `sex` int,\n    `address` Nullable(String),\n    `datetime` Date DEFAULT now()\n) engine = Distributed(test_clu, 'default', 'c_user', rand());\n```\n\nmarcos.xml 参考配置\n\n```xml\n<yandex>\n    <macros replace=\"replace\">\n        <shard>SHARD_NAME</shard> <!--集群ID-->\n        <replica>REPLICA_NAME</replica> <!--副本ID-->\n    </macros>\n</yandex>\n```\n\n> **每个副本都应该唯一**\n\n## 总结\n\nclickhouse用于大数据查询, 占用空间少, 查询速度快\n","tags":["数据库"]},{"title":"cron表达式","url":"/shmily-blog/2019/07/17/cron/","content":"\ncron表达式常用于调度任务\n\n本文摘自:[cron表达式详解](https://www.cnblogs.com/javahr/p/8318728.html)\n\n## 结构\n\ncorn从左到右（用空格隔开）：秒 分 小时 月份中的日期 月份 星期中的日期 年份\n\n## 各字段的含义\n\n字段|允许值|允许的特殊字符\n:-------:|:-----------------------:|:------------:\n秒（Seconds）|0~59的整数|, - * /    四个字符\n分（Minutes）|0~59的整数|, - * /    四个字符\n小时（Hours）|0~23的整数|, - * /    四个字符\n日期（DayofMonth）|1~31的整数（但是你需要考虑你月的天数）|,- * ? / L W C     八个字符\n月份（Month）|1~12的整数或者 JAN-DEC|, - * /    四个字符\n星期（DayofWeek）|1~7的整数或者 SUN-SAT （1=SUN）|, - * ? / L C #     八个字符\n年(可选，留空)（Year）|1970~2099|, - * /    四个字符\n\n## 注意事项\n\n每一个域都使用数字，但还可以出现如下特殊字符，它们的含义是:\n\n1. *：表示匹配该域的任意值。假如在Minutes域使用*, 即表示每分钟都会触发事件。\n2. ?：只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。因为DayofMonth和DayofWeek会相互影响。例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 * ?, 其中最后一位只能用？，而不能使用*，如果使用*表示不管星期几都会触发，实际上并不是这样。\n3. -：表示范围。例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次\n4. /：表示起始时间开始触发，然后每隔固定时间触发一次。例如在Minutes域使用5/20,则意味着从5分开始每20分钟触发一次\n5. ,：表示列出枚举值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发一次。\n6. L：表示最后，只能出现在DayofWeek和DayofMonth域。如果在DayofWeek域使用5L,意味着在最后的一个星期四触发。\n7. W:表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的最近的有效工作日触发事件。例如：在 DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4日触发。如果5日是星期天，则在6日(周一)触发；如果5日在星期一到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨过月份 。\n8. LW:这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。\n9. #:用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月的第二个星期三。\n\n## 常用表达式例子\n\n1. 0 0 2 1 * ? *   表示在每月的1日的凌晨2点调整任务\n2. 0 15 10 ? * MON-FRI   表示周一到周五每天上午10:15执行作业\n3. 0 15 10 ? 6L 2002-2006   表示2002-2006年的每个月的最后一个星期五上午10:15执行作\n4. 0 0 10,14,16 * * ?   每天上午10点，下午2点，4点\n5. 0 0/30 9-17 * * ?   朝九晚五工作时间内每半小时\n6. 0 0 12 ? * WED    表示每个星期三中午12点\n7. 0 0 12 * * ?   每天中午12点触发\n8. 0 15 10 ? * *    每天上午10:15触发\n9. 0 15 10 * * ?     每天上午10:15触发\n10. 0 15 10 * * ? *    每天上午10:15触发\n11. 0 15 10 * * ? 2005    2005年的每天上午10:15触发\n12. 0 * 14 * * ?     在每天下午2点到下午2:59期间的每1分钟触发\n13. 0 0/5 14 * * ?    在每天下午2点到下午2:55期间的每5分钟触发\n14. 0 0/5 14,18 * * ?     在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发\n15. 0 0-5 14 * * ?    在每天下午2点到下午2:05期间的每1分钟触发\n16. 0 10,44 14 ? 3 WED    每年三月的星期三的下午2:10和2:44触发\n17. 0 15 10 ? * MON-FRI    周一至周五的上午10:15触发\n18. 0 15 10 15 * ?    每月15日上午10:15触发\n19. 0 15 10 L * ?    每月最后一日的上午10:15触发\n20. 0 15 10 ? * 6L    每月的最后一个星期五上午10:15触发\n21. 0 15 10 ? * 6L 2002-2005   2002年至2005年的每月的最后一个星期五上午10:15触发\n22. 0 15 10 ? * 6#3   每月的第三个星期五上午10:15触发\n\n## 最后\n\n有些子表达式能包含一些范围或列表\n\n例如：子表达式（天（星期））可以为 “MON-FRI”，“MON，WED，FRI”，“MON-WED,SAT”\n\n“*”字符代表所有可能的值\n\n因此，“*”在子表达式（月）里表示每个月的含义，“*”在子表达式（天（星期））表示星期的每一天\n\n“/”字符用来指定数值的增量 \n例如：在子表达式（分钟）里的“0/15”表示从第0分钟开始，每15分钟 \n在子表达式（分钟）里的“3/20”表示从第3分钟开始，每20分钟（它和“3，23，43”）的含义一样\n\n“？”字符仅被用于天（月）和天（星期）两个子表达式，表示不指定值 \n当2个子表达式其中之一被指定了值以后，为了避免冲突，需要将另一个子表达式的值设为“？”\n\n“L” 字符仅被用于天（月）和天（星期）两个子表达式，它是单词“last”的缩写 \n但是它在两个子表达式里的含义是不同的。 \n在天（月）子表达式中，“L”表示一个月的最后一天 \n在天（星期）自表达式中，“L”表示一个星期的最后一天，也就是SAT\n\n如果在“L”前有具体的内容，它就具有其他的含义了\n\n例如：“6L”表示这个月的倒数第６天，“FRIL”表示这个月的最一个星期五 \n注意：在使用“L”参数时，不要指定列表或范围，因为这会导致问题\n"},{"title":"正则表达式","url":"/shmily-blog/2019/07/17/regular/","content":"\n学习正则表达式\n\n[正则表达式30分钟入门教程](https://deerchao.net/tutorials/regex/regex.htm)\n\n[Python - 100天从新手到大师](https://github.com/jackfrued/Python-100-Days)\n\n## 基本\n\n符号|解释|示例|说明\n:-------:|:-----------------------:|:--------------------------------:|:----------------------------------:\n.|匹配任意字符|b.t|可以匹配bat / but / b#t / b1t等\n\\w|匹配字母/数字/下划线|b\\wt|可以匹配bat / b1t / b_t等但不能匹配b#t\n\\s|匹配空白字符（包括\\r、\\n、\\t等）|love\\syou|可以匹配love you\n\\d|匹配数字|\\d\\d|可以匹配01 / 23 / 99等\n\\b|匹配单词的边界|\\bThe\\b|\n^|匹配字符串的开始|^The|可以匹配The开头的字符串\n$|匹配字符串的结束|.exe$|可以匹配.exe结尾的字符串\n\\W|匹配非字母/数字/下划线|b\\Wt|可以匹配b#t / b@t等但不能匹配but / b1t / b_t等\n\\S|匹配非空白字符|love\\Syou|可以匹配love#you等但不能匹配love you\n\\D|匹配非数字|\\d\\D|可以匹配9a / 3# / 0F等\n\\B|匹配非单词边界|\\Bio\\B|\n[]|匹配来自字符集的任意单一字符|[aeiou]|可以匹配任一元音字母字符\n[^]|匹配不在字符集中的任意单一字符|[^aeiou]|可以匹配任一非元音字母字符\n*|匹配0次或多次|\\w*|\n+|匹配1次或多次|\\w+|\n?|匹配0次或1次|\\w?|\n{N}|匹配N次|\\w{3}|\n{M,}|匹配至少M次|\\w{3,}|\n{M,N}|匹配至少M次至多N次|\\w{3,6}|\n\\||分支|foo|bar|可以匹配foo或者bar\n(?#)|注释||\n(exp)|匹配exp并捕获到自动命名的组中||\n(?<name>exp)|匹配exp并捕获到名为name的组中||\n(?:exp)|匹配exp但是不捕获匹配的文本||\n(?=exp)|匹配exp前面的位置|\\b\\w+(?=ing)|可以匹配I'm dancing中的danc\n(?<=exp)|匹配exp后面的位置|(?<=\\bdanc)\\w+\\b|可以匹配I love dancing and reading中的第一个ing\n(?!exp)|匹配后面不是exp的位置||\n(?<!exp)|匹配前面不是exp的位置||\n*?|重复任意次，但尽可能少重复|a.*b\na.*?b|将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串\n+?|重复1次或多次，但尽可能少重复||\n??|重复0次或1次，但尽可能少重复||\n{M,N}?|重复M到N次，但尽可能少重复||\n{M,}?|重复M次以上，但尽可能少重复||\n"},{"title":"Python3 学习","url":"/shmily-blog/2019/07/04/python3/","content":"\n本篇博客学习总结于[Python - 100天从新手到大师](https://github.com/jackfrued/Python-100-Days)\n\n## Python是一个“优雅”、“明确”、“简单”的编程语言\n\n给初学者的建议:\n\n1. Make English as your working language.\n2. Practice makes perfect.\n3. All experience comes from mistakes.\n4. Don't be one of the leeches.\n5. Either stand out or kicked out.\n\n## Python基础数据类型\n\n1. 整数\n2. 字符串\n3. 浮点数\n4. True/False\n5. None\n\n## Python数据结构\n\n1. List（列表）: 数组\n2. Tuple（元组）: 不可修改列表\n3. Set（集合）: 同数学中的集合, 不可重复, 可以技术 交集、并集、差集等运算\n4. Dictionary（字典）: 每一个元素都是由 “键值对” 组成\n\n## 字符串格式化代码\n\n参数|说明\n:----:|:----------------------------:\n%%|百分号标记\n%c|字符及其ASCII码\n%s|字符串\n%d|有符号整数(十进制)\n%u|无符号整数(十进制)\n%o|无符号整数(八进制)\n%x|无符号整数(十六进制)\n%X|无符号整数(十六进制大写字符)\n%e|浮点数字(科学计数法)\n%E|浮点数字(科学计数法，用E代替e)\n%f|浮点数字(用小数点符号)\n%g|浮点数字(根据值的大小采用%e或%f)\n%G|浮点数字(类似于%g)\n%p|指针(用十六进制打印值的内存地址)\n%n|存储输出字符的数量放进参数列表的下一个变量中\n\n## 算术运算符\n\n运算符|描述|实例\n:------:|:--------------------:|:----------:\n+|加 - 两个对象相加|a + b 输出结果 31\n-|减 - 得到负数或是一个数减去另一个数|a - b 输出结果 -11\n*|乘 - 两个数相乘或是返回一个被重复若干次的字符串|a * b 输出结果 210\n/|除 - x 除以 y|b / a 输出结果 2.1\n%|取模 - 返回除法的余数|b % a 输出结果 1\n**|幂 - 返回x的y次幂|a**b 为10的21次方\n//|取整除 - 向下取接近除数的整数|9//2 = 4; -9//2 = -5\n\n## 特殊运算符\n\n运算符|描述\n:-----:|:--------------------:\n&|在set求交集的时候,同set1.intersection(set2)\n\\||在set求并集的时候,同set1.union(set2)\n-|在set求差集的时候,同set1.difference(set2)\n^|在set求对称差的时候,同set1.symmetric_difference(set2)\n\n## 文件操作符\n\n### python内置的 `open` 函数\n\n操作模式|具体含义\n:----:|:--------------------:\n'r'|读取 （默认）\n'w'|写入（会先截断之前的内容）\n'x'|写入，如果文件已经存在会产生异常\n'a'|追加，将内容写入到已有文件的末尾\n'b'|二进制模式\n't'|文本模式（默认）\n'+'|更新（既可以读又可以写）\n\n### python的`JSON`模块\n\n常用的四个函数\n\n+ dump - 将Python对象按照JSON格式序列化到文件中\n+ dumps - 将Python对象处理成JSON格式的字符串\n+ load - 将文件中的JSON数据反序列化成对象\n+ loads - 将字符串的内容反序列化成Python对象\n\n这里出现了两个概念，一个叫序列化，一个叫反序列化。自由的百科全书维基百科上对这两个概念是这样解释的：“序列化（serialization）在计算机科学的数据处理中，是指将数据结构或对象状态转换为可以存储或传输的形式，这样在需要的时候能够恢复到原先的状态，而且通过序列化的数据重新获取字节时，可以利用这些字节来产生原始对象的副本（拷贝）。与这个过程相反的动作，即从一系列字节中提取数据结构的操作，就是反序列化（deserialization）”。\n\n### 实际操作\n\n```python\n#!/usr/local/bin/python3\n\"\"\"\n文件操作和异常处理及JSON数据\n\"\"\"\n\nimport json\n\n\ndef read():\n    \"\"\"读取文件\"\"\"\n    try:\n        fs = open('a.txt', 'r', encoding='utf-8')\n        print(fs.read())\n    except FileNotFoundError:\n        print('文件不存在')\n    finally:\n        if fs:\n            fs.close()\n\n\ndef writh(cmd='w'):\n    \"\"\"写文件\"\"\"\n    try:\n        txt = (x for x in range(600, 1000))\n        fs = open('b.txt', cmd, encoding='utf-8')\n        for t in txt:\n            fs.write(str(t) + '\\n')\n    except IOError:\n        print('IO异常')\n    finally:\n        if fs:\n            fs.close()\n\n\ndef with_def():\n    \"\"\"\n    使用with关键字,指定文件对象的上下文环境并在离开上下文环境时自动释放文件资源\n    \"\"\"\n    try:\n        \"\"\"一次读取所有文件\"\"\"\n        with open('a.txt', 'r', encoding='utf-8') as f1:\n            print(f1.read())\n\n        \"\"\"使用for-in逐行读取\"\"\"\n        with open('a.txt', encoding='utf-8', mode='r') as f2:\n            for line in f2:\n                print(line, end='')\n    except Exception:\n        print('错误', Exception)\n\n\ndef buffer_file_def():\n    \"\"\"读取二进制文件(拷贝图片)\"\"\"\n    try:\n        \"\"\"复制文件\"\"\"\n        with open('/Users/aolei/Pictures/my images/32916897.jpg', mode='rb') as f:\n            data = f.read()\n            print(data)\n\n        \"\"\"粘贴到当前目录下\"\"\"\n        with open('head.jpg', mode='wb') as f:\n            f.write(data)\n            print('Copy Success')\n    except FileNotFoundError :\n        print('文件不存在')\n    except UnicodeEncodeError:\n        print('编码异常')\n\n\ndef json_data_def():\n    \"\"\"python对json数据的处理\"\"\"\n    myuser = {\n        'name':'李黑',\n        'sex': '男',\n        'age': 0,\n        'qq': 957658,\n        'friends': ['王大锤', '白元芳'],\n        'cars': [\n            {'brand': 'BYD', 'max_speed': 180},\n            {'brand': 'Audi', 'max_speed': 280},\n            {'brand': 'Benz', 'max_speed': 320}\n        ]\n    }\n\n    try:\n        \"\"\"将python字典对象序列化为json文件\"\"\"\n        with open('users.json', 'w', encoding='utf-8') as f:\n            json.dump(myuser, f)\n\n        \"\"\"将json文件反序列化为python字典对象\"\"\"\n        with open('users.json', 'r', encoding = 'utf-8') as f:\n            curr_user = json.load(f)\n            print(curr_user)\n    except IOError:\n        print('文件写入失败')\n\n\nif __name__ == \"__main__\":\n    # read()\n    # writh('a')\n    # with_def()\n    # buffer_file_def()\n    json_data_def()\n```\n\n## 参考\n\n[《总结：Python中的异常处理》](https://segmentfault.com/a/1190000007736783 \"思否 - 总结：Python中的异常处理\")\n\n[HTTP协议入门](http://www.ruanyifeng.com/blog/2016/08/http.html \"阮一峰HTTP协议入门\")\n\n[聚合数据](https://www.juhe.cn/ \"聚合数据\")\n\n[阿凡达数据](https://www.avatardata.cn/ \"阿凡达数据\")\n\n## 结语\n\n> Don't be one of the leeches.\n\n![ ](./1.png)\n","tags":["编程语言"]},{"title":"Shell学习笔记","url":"/shmily-blog/2019/06/18/shell/","content":"\nShell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁\n\nShell 编程跟 java、php 编程一样，只要有一个能编写代码¸的文本编辑器和一个能解释执行的脚本解释器就可以了。\n\n## 开始\n\n### 创建脚本文件\n\n新建一个扩展名为`.sh`的文件`test.sh`, sh代表*shell*\n\ntest.sh文件内容如下:\n\n```sh\n#!/bin/bash\necho \"Hello Shell\"\n```\n\n> `#!` 是一个约定俗成的标记, 用于告诉系统使用哪个解释器来执行这个脚本.  \n> `echo` 命令是用于向终端输出文本信息,也可用于向文件中写入数据\n\n### 运行shell脚本\n\n运行shell脚本的方式两种\n\n+ 通过可执行文件运行\n\n需要给脚本文件添加可执行权限\n\n```sh\n# 在 test.sh 文件所在的文件夹下, 执行以下命令\nchmod +x ./test.sh\n```\n\n> 这里需要注意的是, 一定要写成`./test.sh`而不是`test.sh`, 否责系统可能会找不到脚本文件, `./`的意思是 指定在当前文件路径下查找文件\n\n+ 作为解释器参数\n\n```sh\n/bin/sh test.sh\n/bin/php test.php\n```\n\n> 这种方式下,在文件第一行添加*标记*也没有效果(因为你已经指定了解释器来运行脚本)\n\n## 变量\n\n规则:\n\n1. 定义变量时，变量名不加美元符号\n2. 变量名和等号之间不能有空格\n3. 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。\n4. 中间不能有空格，可以使用下划线（_）。\n5. 不能使用标点符号。\n6. 不能使用bash里的关键字（可用help命令查看保留关键字）。\n\n示例:\n\n有效命名:\n\n```sh\nRUNOOB\nLD_LIBRARY_PATH\n_var\nvar2\n```\n\n无效命名:\n\n```sh\n?var=123\nuser*name=runoob\n```\n\n显示赋值\n\n`your_name=\"runoob.com\"`\n\n通过语句赋值\n\n```sh\nfor file in `ls /etc`\n# 或\nfor file in $(ls /etc)\n```\n\n> 以上语句, 列出`/etc`路径下的所有文件名,赋值给`file`\n\n### 使用变量\n\n使用变量,只需要在变量前面加一个`$`符号\n\n```sh\nname=\"shell\"\necho $name\necho ${name}\n```\n\n`$name`和`${name}`都是可以的, `{}`是可选的, 它的作用是帮助解释器来识别变量边界的, 比如:\n\n```sh\nfor skill in Ada Coffe Action Java; do\n    echo \"I am good at ${skill}Script\"\ndone\n```\n\n如果不加 `{}` 则解释器认为`$skillScript`是一个变量(内容为空),\n\n>> 推荐给所有的变量加上`{}`,养成好的编程习惯\n\n### 只读变量\n\n已经定义的变量可以被重新赋值, **只读变量**除外\n\n定义方式为: 在变量前面加上 `readonly`\n\n```sh\nreadonly name=\"Shell\"\nname=\"jason\" # 这里会报错  error: NAME: This variable is read only.\n```\n\n### 删除变量\n\n```sh\nunset name\n```\n\n> unset 命令不能删除只读变量。 删除之后不能使用\n\n## 参考\n\n[菜鸟教程](https://www.runoob.com/linux/linux-shell.html \"Linux Shell教程\")\n\n## 结语\n\n学习一门技术, 开始的时候不要纠结各种看不懂的语法、不钻牛角尖, 先培养兴趣, 再循序渐进.\n","tags":["脚本语言"]},{"title":"mysql学习笔记","url":"/shmily-blog/2019/06/05/mysql5-7/","content":"\n这篇文章主要是我日常使用mysql的一些记录\n我使用的mysql版本是:`5.7`\n\n## MySQL 相关文章\n\n[【链接】大牛总结的MySQL锁优化，写得太好了！](https://cloud.tencent.com/developer/news/456119)\n[【链接】一篇文章弄懂MySQL的事务隔离级别](https://mp.weixin.qq.com/s/p32Tc6XhbHq_NbJWAiZnhQ)\n\n## 用户\n\n### 创建用户\n\n```sh\ncreate user 'testuser'@'%' identified by 'password';\n```\n\n创建 `testuser` 用户, 可以在所有主机上登陆使用, 密码为`password`;\n\n1. testuser 是创建的用户名\n2. % 是主机名,指定哪些主机可以使用改用户\n   1. %/0.0.0.0 所有主机可以使用\n   2. localhost/127.0.0.1 本机可以使用\n   3. ...\n3. password 是创建的用户登陆密码, 如果指定为 `identified by ''` 则不设置密码\n\n### 删除用户\n\n```sh\ndrop user 'apollo'@'%';\n```\n\n### 用户权限\n\n#### 授予权限\n\n```sh\ngrant all on testdb.* to 'testuser'@'%';\ngrant select on testdb.* to 'testuser'@'%';\ngrant insert on testdb.* to 'testuser'@'%';\n```\n\n授予用户`testuser`在所有主机上使用`testdb`数据库下**所有表**的权限\n\n+ all 代表权限\n  + select 查询权限\n  + insert 插入权限\n  + delete 删除权限\n  + update 修改权限\n+ testdb.* 改数据库下的所有表\n+ 'testuser'@'%' 表示`testuser`在`%`主机可以使用授予的权限\n\n#### 刷新权限\n\n`flush privileges;`\n\n#### 删除权限\n\n```sh\nREVOKE ALL ON test.* FROM 'testuser'@'%';\nREVOKE select ON test.* FROM 'testuser'@'%';\nREVOKE insert ON test.* FROM 'testuser'@'%';\n```\n\n+ 删除所有权限\n+ 删除查询权限\n+ 删除插入权限\n\n#### 查看用户权限\n\n`SHOW GRANTS FOR 'testuser'@'%';`\n\n## 数据库\n\n### 基本语法\n\n#### 函数\n\n##### 类型转换函数\n\n用于类型转化 CAST()和CONVERT()\n\n```sh\nCAST(value as type);\nCONVERT(value, type);\n```\n\n可以转换的类型是有限制的。这个类型可以是以下值其中的一个：\n\n+ 二进制，同带binary前缀的效果 : BINARY\n+ 字符型，可带参数 : CHAR()\n+ 日期 : DATE\n+ 时间: TIME\n+ 日期时间型 : DATETIME\n+ 浮点数 : DECIMAL\n+ 整数 : SIGNED\n+ 无符号整数 : UNSIGNED\n\n示例:\n\n```sh\n# 1\nmysql> SELECT CONVERT('23',SIGNED);\n+----------------------+\n| CONVERT('23',SIGNED) |\n+----------------------+\n|                   23 |\n+----------------------+\n1 row in set\n\n# 2\nmysql> SELECT CAST('125e342.83' AS signed);\n+------------------------------+\n| CAST('125e342.83' AS signed) |\n+------------------------------+\n|                          125 |\n+------------------------------+\n1 row in set\n\n# 3\nmysql> SELECT CAST('3.35' AS signed);\n+------------------------+\n| CAST('3.35' AS signed) |\n+------------------------+\n|                      3 |\n+------------------------+\n1 row in set\n```\n\n##### 格式化函数\n\n##### 随机数 rand()\n\n```sh\nselect rand()\n```\n\n#### 时间\n\n##### 获取系统时间 `now()` 和 `sysdate()` 这两个函数的区别是, `now()`在执行前就确认了值, `sysdate()`在执行时动态确认值\n\n例子:\n\n```sh\n> select now(), sleep(3), now();\n> select sysdate(), sleep(3), sysdate();\n```\n\n> 感兴趣的可以看一下这两天sql执行的结果\n\n##### 获得当前时间戳函数：current_timestamp, current_timestamp()\n\n语法: `select current_timestamp, current_timestamp()`\n\n##### 日期、时间转换\n\n时间转换为字符串 date_format(date,format), time_format(time,format)\n\n时间格式化函数 DATE_FORMAT(date, format)\n\n1. date 时间\n2. format 参数格式有\n\n参数|说明\n:----:|:-----------------------:\n%a|缩写星期名\n%b|缩写月名\n%c|月，数值\n%D|带有英文前缀的月中的天\n%d|月的天，数值(00-31)\n%e|月的天，数值(0-31)\n%f|微秒\n%H|小时 (00-23)\n%h|小时 (01-12)\n%I|小时 (01-12)\n%i|分钟，数值(00-59)\n%j|年的天 (001-366)\n%k|小时 (0-23)\n%l|小时 (1-12)\n%M|月名\n%m|月，数值(00-12)\n%p|AM 或 PM\n%r|时间，12-小时（hh:mm:ss AM 或 PM）\n%S|秒(00-59)\n%s|秒(00-59)\n%T|时间, 24-小时 (hh:mm:ss)\n%U|周 (00-53) 星期日是一周的第一天\n%u|周 (00-53) 星期一是一周的第一天\n%V|周 (01-53) 星期日是一周的第一天，与 %X 使用\n%v|周 (01-53) 星期一是一周的第一天，与 %x 使用\n%W|星期名\n%w|周的天 （0=星期日, 6=星期六）\n%X|年，其中的星期日是周的第一天，4 位，与 %V 使用\n%x|年，其中的星期一是周的第一天，4 位，与 %v 使用\n%Y|年，4 位\n%y|年，2 位\n\n字符串转换为时间 str_to_date(str, format)\n\n(日期、天数）转换函数：to_days(date), from_days(days)\n\n(时间、秒）转换函数：time_to_sec(time), sec_to_time(seconds)\n\n拼凑日期、时间函数：makdedate(year,dayofyear), maketime(hour,minute,second)\n\nUnix 时间戳、日期）转换函数\n\n1. unix_timestamp(),\n2. unix_timestamp(date),\n3. from_unixtime(unix_timestamp),\n4. from_unixtime(unix_timestamp,format)\n   1. 格式化函数 FROM_UNIXTIME(unix_timestamp, [format])\n   2. unix_timestamp 一般为10位的时间戳，如:1417363200\n   3. format *可选* 转换之后的时间字符串显示的格式;\n\n##### 日期时间计算函数\n\n增加一个时间间隔：DATE_ADD(date,INTERVAL expr type)\n\n+ date 要操作的时间\n+ expr 要添加的时间间隔\n+ type 参考下表\n\ntype的值|备注\n:----------:|:-------:\nMICROSECOND|\nSECOND|秒\nMINUTE|分\nHOUR|小时\nDAY|天\nWEEK|星期\nMONTH|月\nQUARTER|?\nYEAR|年\nSECOND_MICROSECOND|\nMINUTE_MICROSECOND|\nMINUTE_SECOND|\nHOUR_MICROSECOND|\nHOUR_SECOND|\nHOUR_MINUTE|\nDAY_MICROSECOND|\nDAY_SECOND|\nDAY_MINUTE|\nDAY_HOUR|\nYEAR_MONTH|\n\n> adddate(), addtime()函数，可以用 date_add() 来替代\n\n日期减去一个时间间隔：DATE_SUB(date,INTERVAL expr type)\n\n> DATE_SUB(date,INTERVAL expr type) 日期时间函数 和 date_add() 用法一致\n\n日期、时间相减函数：datediff(date1,date2), timediff(time1,time2)\n\n1. datediff 返回天数差距\n2. timediff 返回time差距\n\n> 注意：timediff(time1,time2) 函数的两个参数类型必须相同。\n\n时间戳（timestamp）转换、增、减函数\n\n1. timestamp(date) -- date to timestamp\n2. timestamp(dt,time) -- dt + time\n3. timestampadd(unit,interval,datetime_expr) --\n4. timestampdiff(unit,datetime_expr1,datetime_expr2) --\n\n示例:\n\n```sh\nselect timestamp('2008-08-08'); -- 2008-08-08 00:00:00\nselect timestamp('2008-08-08 08:00:00', '01:01:01'); -- 2008-08-08 09:01:01\nselect timestamp('2008-08-08 08:00:00', '10 01:01:01'); -- 2008-08-18 09:01:01\n\nselect timestampadd(day, 1, '2008-08-08 08:00:00'); -- 2008-08-09 08:00:00\nselect date_add('2008-08-08 08:00:00', interval 1 day); -- 2008-08-09 08:00:00\n\ntimestampadd() 函数类似于 date_add()。\nselect timestampdiff(year,'2002-05-01','2001-01-01'); -- -1\nselect timestampdiff(day ,'2002-05-01','2001-01-01'); -- -485\nselect timestampdiff(hour,'2008-08-08 12:00:00','2008-08-08 00:00:00'); -- -12\n\nselect datediff('2008-08-08 12:00:00', '2008-08-01 00:00:00'); -- 7\n```\n\n> timestampdiff() 函数就比 datediff() 功能强多了，datediff() 只能计算两个日期（date）之间相差的天数。\n\n时区（timezone）转换函数\n\n```sh\nconvert_tz(dt,from_tz,to_tz)\n\nselect convert_tz('2008-08-08 12:00:00', '+08:00', '+00:00'); -- 2008-08-08 04:00:00\n```\n\n> 时区转换也可以通过 date_add, date_sub, timestampadd 来实现\n\n## 相关链接\n\n[MySQL CAST与CONVERT 函数的用法](https://www.cnblogs.com/chenqionghe/p/4675844.html)\n\n[MySQL 日期格式](https://www.cnblogs.com/dest/p/4205371.html)\n\n## 结语\n\n每天都要去折腾才能进步\n","tags":["数据库"]},{"title":"Docker学习笔记","url":"/shmily-blog/2019/05/16/docker/","content":"\n我是一个java程序猿, 当前已经转为nodejs开发, 因为工作需要接触docker到目前为止已经有一年多的时间了, 一下是我学习和使用docker的一些总结.\n\n## 前言\n\n### 认识docker\n\nDocker是一个容器平台, 可以说他是一个虚拟机平台, 但是它又比虚拟机强大. Docker是开发人员和系统管理员使用容器开发，部署和运行应用程序的平台。\n使用Linux容器部署应用程序称为容器化。容器不是新的，但它们用于轻松部署应用程序。\n\n### docker能解决什么问题\n\n1. 生产开发环境不一致的问题\n\n### 基本概念\n\n1. 容器\n2. 镜像\n3. 仓库\n\n## 安装\n\n[参考这里](https://docs.docker.com/install/)\n\n```bash\n# 查看docker版本\ndocker --version\n\n# 查看docker信息\ndocker info\n\n# 测试docker是否安装成功\ndocker run hello-world\n\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nca4f61b1923c: Pull complete\nDigest: sha256:ca0eeb6fb05351dfc8759c20733c91def84cb8007aa89a5bf606bc8b315b9fc7\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n...\n```\n\n## 入门\n\n前提条件: 安装好Docker\n\n### 容器\n\n#### 创建Dockerfile文件\n\n在项目根目录下创建一个Dockerfile文件, 如:\n\n```Dockerfile\n# 将官方 node:9.3.0-alpine 运行时用作父镜像\nFROM node:9.3.0-alpine\n\nRUN mkdir -p /app\n# 将工作目录设置为 /app\nWORKDIR /app\n\n# 将当前目录内容复制到位于 /app 中的容器中\nCOPY . /app/temp\n\nRUN cp /app/temp/package.json /app/package.json &&\\\n    npm install --registry=https://registry.npm.taobao.org &&\\\n    cp -r /app/temp/pages /app/pages &&\\\n    cp -r /app/temp/components /app/components &&\\\n    cp -r /app/temp/next.config.js /app/next.config.js &&\\\n    rm -rf /app/temp\n\n# 在容器启动时运行\nCMD [\"npm\", \"start\"]\n```\n\n有关Dockerfile的命令可以参考这里[编写Dockerfile的最佳实践](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)\n\n#### 构建镜像\n\n命令:\n\n`docker build -t <image-name> .`;\n\n> -t image-name 是给镜像添加名称  \n> . 代表当前根目录  \n> 可选参数 -f Dockerfile-name 指定Dockerfile文件, 默认是 Dockerfile, 当我们有如: MYSQL.Dockerfile 则可以使用该参数指定 例: `docker build -t imagename . -f MySQL.Dockerfile`\n\n#### 运行容器\n\n命令:\n\n`docker run -d -p 3000:3000 --name <容器名称> <镜像hashid/镜像名称>`\n\n1. -d 参数指定容器在后台运行\n2. -p 指定容器端口映射, 主机端口:容器端口, 容器端口指容器内部服务对外暴露的端口,如果tomcat对外提供服务的端口为8080\n3. --name 参数设置容器名称\n4. 最后接对应的镜像 hashid 或者 镜像名称:tag\n\n其他常用参数:\n\n1. --network 指定容器运行的网络环境\n2. -v 配置容器数据卷, 更多信息参考 高级篇[容器数据]\n3. --rm 该命令常常与 -v 一起使用, 在删除/停止容器的时候同事清除数据卷映射关系\n4. --link 链接到其他容器, 新版本推荐使用 --network 指定容器网络环境即可\n\n容器镜像操作:\n\n```bash\ndocker ps; #查看当前运行的容器\ndocker ps -a; # 查看所有的容器\ndocker logs <镜像hashid/镜像名称> # 查看指定容器的日记\ndocker start <容器hashid/容器名称> # 启动容器\ndocker stop <容器hashid/容器名称> # 停止容器\ndocker stop -f <镜像hashid/镜像名称> # 停止容器, 同时删除容器\ndocker rm <容器hashid/容器名称>... # 删除容器, 可以同时指定多个 <容器hashid/容器名称>\ndocker rmi <镜像hashid/镜像名称> # 删除镜像, 必须注意的是, 先删除容器才能删除镜像\n```\n\n推送镜像到仓库\n\n1. 登陆docker仓库 `docker login ...`\n2. 给镜像打标签 `docker tag [本地镜像名称]:[版本号] [存储库名称]:[版本号]`\n3. 推送到镜像仓库 `docker push [账号名]/[存储库名称]:[版本号]`\n4. 尝试拉取镜像 `docker pull [账号名]/[存储库名称]:[版本号]`\n\n案例\n\n```sh\n# 登陆dockerhub\ndocker login\n\n# 构建镜像\ndocker build -t arm64v8/myblog:latest .\n\n# 将本地镜像打标签\ndocker tag arm64v8/myblog:latest jiangzwyz/myblog:latest\n\n# 推送到镜像仓库\ndocker push jiangzwyz/myblog:latest\n```\n\n### 服务Swarms\n\n待补充\n\n## 高级篇\n\n### 容器数据\n\n深入了解docker的都会知道docker的方便,但是也会明白docker的缺点,就是容器在被销毁时,其内部的数据将会全部丢失,那么这里我们就将解决这个问题\n\n最常见的案例就是数据库了, 这里我们以配置 mysql容器为例, 示范如何使用**数据卷**将容器的数据保存到主机上.\n\nDockerfile文件:\n\n```Dockerfile\n# 拉取 mysql:5.7 官方镜像\nFROM mysql:5.7\n\n# 设置时区 Shanghai\nRUN cp /usr/share/zoneinfo/PRC /etc/localtime\n\n# ENV 设置 镜像环境变量 mysql 镜像参考官方说明,可以在此配置账户密码\nENV MYSQL_ROOT_PASSWORD=you_password\nENV MYSQL_USER=you_name\nENV MYSQL_PASSWORD=you_passowrd\n\n# 这里我使用了自定义mysql的配置文件\nCOPY ./mysql/mysql.cnf /etc/mysql/conf.d/mysql.cnf\nCOPY ./mysql/mysqld.cnf /etc/mysql/mysql.conf.d/mysqld.cnf\n```\n\n**重点**在这里\n\n```bash\ndocker build -t mysql . -f MYSQL.Dockerfile;\ndocker run -d -p 3306:3306 --rm -v /mysql/db:/var/lib/mysql --name mysql mysql;\n```\n\n从当前项目中构建mysql镜像, 然后运行容器时指定主机/mysql/db目录挂载到容器/var/lib/mysql目录(此目录是mysql数据库文件所在)\n\n数据类的容器,官方都会说明其数据文件存放的位置, 当然我们也可以挂载网盘到容器中.\n\n![ ](/../img/docker_01.png)\n\n### 容器网络\n\n#### 使用容器,你就不应该再去管理烦人的IP\n\n我们载部署项目的时候经常会遇到这个问题, 我们的项目需要连接mysql, 一般我们通过ip去连接*(localhost:3306、127.0.0.1:3306), 这样到还简单,如果我们的mysql IP是动态的, 怎么办? 你改的几次就会抓狂的. 所以我们需要使用到 容器网络  network\n\n#### 在Docker中建立 自定义 桥网络\n\n1. 连接到默认bridge网络的容器可以通过IP地址相互通信。Docker不支持默认网桥上的自动服务发现。如果希望容器能够按容器名称解析IP地址，则应使用用户定义的网络。您可以使用旧版docker run --link选项将两个容器链接在一起，但在大多数情况下不建议这样做。\n2. 使用自定义 bridge网络 运行在其中的容器可以发现对方\n3. 要实现 容器间通讯，采用 自定义 桥网络 （容器必须在同一主机中）\n4. network  桥网络，容器运行再 用户自定义桥网络 中，容器间可以通过 局域网访问（**不适用于分布式主机**），默认桥网络不支持这样\n\n```bash\n# 查看当前主机中网络列表\n$ docker network ls\n\n# 创建 桥网络\n$ docker network create --driver bridge [network-name]\n\n# 将容器运行在对应的 bridge网络 中，使用 --network=[network-name]\n$ docker run -d -p 80:80 -p 443:443 --network=[network-name] --name mynginx [container-images-id]\n$ docker run -d -p 80:80 -p 443:443 --rm -v ~/../workspace/myimages/images:/app/images &&\\\n  --network=[network-name] & --name=1.2.3.4 [container-images-id]\n```\n\n在同一个 network 网络中的两个容器之间通信可以直接使用 容器名称:端口 的方式去访问,\n如: mysql:3306\n\n### k8s\n\n容器编排\n\n## 其他\n\n### 设置容器时区\n\n时区问题一直都是我们需要解决的问题, 容器同样避免不了这个问题.\n\n在linux中, 我们可以将本地时间文件拷贝到/etc/localtime即可设置容器时间\n\nlinux的时区设置文件在 /usr/share/zoneinfo/Asia\n\n我们将设置系统时间为 上海 例:\n\n```bash\n# 在Dockerfile中添加:\n\n# linux版本: node:9.3.0-alpine\nRUN apk add --no-cache tzdata && \\\n    cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo \"Asia/Shanghai\" > /etc/timezone && \\\n    apk del tzdata\n\n# 镜像 mysql:5.7\nRUN cp /usr/share/zoneinfo/PRC /etc/localtime\n```\n\n> 上海时区/usr/share/zoneinfo/Asia/Shanghai实际上是链接到/usr/share/zoneinfo/PRC时区, 所以在第二个中我们的做法也是可取的.\n\n## 结语\n\n官方文档是最好的学习资料\n","tags":["容器"]},{"title":"Nginx学习笔记","url":"/shmily-blog/2019/05/15/nginx/","content":"\nNginx是一个**轻量级的高性能**HTTP和反向代理服务器, 由俄罗斯人 **伊戈尔·赛索耶夫**\n\n> 这是一个学习笔记, 我想它应该不需要那么详细\n\n## 安装 Nginx\n\n我们既然学习了Docker, 那就要使用Docker\n\n使用 Docker 安装 Nginx\n\n```bash\n# 从docker hub中查找nginx\ndocker search nginx\n\n# 拉取nginx官方最新稳定版 nginx 镜像\ndocker pull nginx\n\n# 启动 nginx 镜像\ndocker run -d -p 80:80 --name nginx nginx\n```\n\n## Nginx基本概念\n\n### 正则表达式\n\n1. ~  表示执行一个正则匹配，区分大小写\n2. ~* 表示执行一个正则匹配，不区分大小写\n3. ^~ 表示普通字符匹配。使用前缀匹配。如果匹配成功，则不再匹配其他location。\n4. =  进行普通字符精确匹配。也就是完全匹配。\n5. @  它定义一个命名的 location，使用在内部定向时，例如 error_page, try_files\n\n### 匹配规则优先级\n\n1. 等号类型（=）的优先级最高。一旦匹配成功，则不再查找其他匹配项。\n2. ^~类型表达式。一旦匹配成功，则不再查找其他匹配项。\n3. 正则表达式类型（~ ~*）的优先级次之。如果有多个location的正则能匹配的话，则使用正则表达式最长的那个。\n4. 常规字符串匹配类型。按前缀匹配。\n\n### 文件及目录匹配\n\n1. -f和!-f用来判断是否存在文件\n2. -d和!-d用来判断是否存在目录\n3. -e和!-e用来判断是否存在文件或目录\n4. -x和!-x用来判断文件是否可执行\n\n### rewrite(重定向)指令的最后一项参数为flag标记，flag标记有\n\n1. last 相当于apache里面的[L]标记，表示rewrite。\n2. break 本条规则匹配完成后，终止匹配，不再匹配后面的规则。\n3. redirect 返回302临时重定向，浏览器地址会显示跳转后的URL地址。\n4. permanent 返回301永久重定向，浏览器地址会显示跳转后的URL地址。\n\n> 使用last和break实现URI重写，浏览器地址栏不变。  \n> 使用alias指令必须用last标记;  \n> 使用proxy_pass指令时，需要使用break标记。  \n> Last标记在本条rewrite规则执行完毕后，会对其所在server{......}标签重新发起请求.  \n> break标记则在本条规则匹配完成后，终止匹配。\n\n## Nginx配置文件\n\n```conf\n# nginx进程数，建议设置为等于CPU总核心数.\nworker_processes 8;\n\n# 全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]\nerror_log /var/log/nginx/error.log info;\n\n# 进程文件\npid /var/run/nginx.pid;\n\n# 一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。\nworker_rlimit_nofile 65535;\n\n# 工作模式与连接数上限\nevents\n{\n　　#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。\n　　use epoll;\n　　#单个进程最大连接数（最大连接数=连接数*进程数）\n　　worker_connections 65535;\n}\n\n# 设定http服务器\nhttp\n{\n\n    include mime.types; #文件扩展名与文件类型映射表\n    default_type application/octet-stream; #默认文件类型\n    #charset utf-8; #默认编码\n    server_names_hash_bucket_size 128; #服务器名字的hash表大小\n    client_header_buffer_size 32k; #上传文件大小限制\n    large_client_header_buffers 4 64k; #设定请求缓\n    client_max_body_size 8m; #设定请求缓\n    sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。\n    autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。\n    tcp_nopush on; #防止网络阻塞\n    tcp_nodelay on; #防止网络阻塞\n    keepalive_timeout 120; #长连接超时时间，单位是秒\n\n    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。\n    fastcgi_connect_timeout 300;\n    fastcgi_send_timeout 300;\n    fastcgi_read_timeout 300;\n    fastcgi_buffer_size 64k;\n    fastcgi_buffers 4 64k;\n    fastcgi_busy_buffers_size 128k;\n    fastcgi_temp_file_write_size 128k;\n\n    #gzip模块设置\n    gzip on; #开启gzip压缩输出\n    gzip_min_length 1k; #最小压缩文件大小\n    gzip_buffers 4 16k; #压缩缓冲区\n    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）\n    gzip_comp_level 2; #压缩等级\n    gzip_types text/plain application/x-javascript text/css application/xml;\n    #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。\n    gzip_vary on;\n    #limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用\n\n    # 应用 myblog 是容器网络中的昵称\n    upstream blogs {\n        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。\n        # 单台机器 weight 设置无意义\n        server myblog:3001 weight=3;\n    }\n\n    # 虚拟主机的配置\n    server\n    {\n\n        listen 80;　　　　#监听端口\n\n        server_name aa.cn www.aa.cn ; #server_name end  #域名可以有多个，用空格隔开\n\n        index index.html index.htm index.php;  # 设置访问主页\n\n        set $subdomain '';  # 绑定目录为二级域名 bbb.aa.com  根目录 /bbb  文件夹\n\n        if ( $host ~* \"(?:(\\w+\\.){0,})(\\b(?!www\\b)\\w+)\\.\\b(?!(com|org|gov|net|cn)\\b)\\w+\\.[a-zA-Z]+\" )\n        {\n            set $subdomain \"/$2\";\n        }\n\n        root /home/wwwroot/aa.cn/web$subdomain;# 访问域名跟目录  \n\n        include rewrite/dedecms.conf; #rewrite end   #载入其他配置文件\n\n\n        location ~ .*.(php|php5)?$\n        {\n        　　fastcgi_pass 127.0.0.1:9000;\n        　　fastcgi_index index.php;\n        　　include fastcgi.conf;\n        }\n        #图片缓存时间设置\n        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$\n        {\n        　　expires 10d;\n        }\n        #JS和CSS缓存时间设置\n        location ~ .*.(js|css)?$\n        {\n        　　expires 1h;\n        }\n\n    }\n\n    # 日志格式设定\n\n    log_format access '$remote_addr - $remote_user [$time_local] \"$request\" '\n    '$status $body_bytes_sent \"$http_referer\" '\n    '\"$http_user_agent\" $http_x_forwarded_for';\n    #定义本虚拟主机的访问日志\n    access_log /var/log/nginx/ha97access.log access;\n\n    #对 \"/\" 启用反向代理\n    location / {\n\n        proxy_pass http://127.0.0.1:88;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        #以下是一些反向代理的配置，可选。\n        proxy_set_header Host $host;\n        client_max_body_size 10m; #允许客户端请求的最大单文件字节数\n        client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，\n        proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)\n        proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)\n        proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)\n        proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n        proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置\n        proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）\n        proxy_temp_file_write_size 64k;\n        #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n\n    }\n\n    # 设定查看Nginx状态的地址\n    location /NginxStatus {\n\n        stub_status on;\n        access_log on;\n        auth_basic \"NginxStatus\";\n        auth_basic_user_file conf/htpasswd;\n        #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。\n\n    }\n\n    #本地动静分离反向代理配置\n    #所有jsp的页面均交由tomcat或resin处理\n    location ~ .(jsp|jspx|do)?$ {\n\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_pass http://127.0.0.1:8080;\n\n    }\n    #所有静态文件由nginx直接读取不经过tomcat或resin\n    location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$\n    {\n        expires 15d;\n    }\n    location ~ .*.(js|css)?$\n    {\n        expires 1h;\n    }\n\n}\n```\n\n### 使用记录\n\n#### nginx热更新\n\n在docker中,实现nginx热更新 `docker exec -i [nginx容器名/id] nginx -s reload`\n\n### nginx 日志配置\n\n[日志配置 参考](https://www.cnblogs.com/biglittleant/p/8979856.html)\n\n## 进阶使用\n\n再文章开始, 我们使用docker安装nginx, 我们完全使用了nginx官方的默认配置, 这里我们将使用自定义配置来启动nginx\n\n首先我们得知道 nginx 官方 docker 镜像得conf文件位置在哪\n\n我得nginx版本conf文件在: /etc/nginx/nginx.conf (可能不同版本的配置文件会有所不同, 所以我们在拉取镜像的时候最好固定版本)\n\n## 相关链接\n\n[Nginx配置文件nginx.conf详解](https://www.cnblogs.com/xuey/p/7631690.html)\n\n[nginx的location配置详解](https://www.cnblogs.com/sign-ptk/p/6723048.html)\n\n## 结语\n\n","tags":["服务器"]},{"title":"IIS服务器学习","url":"/shmily-blog/2019/05/15/iis/","content":"\nIIS是Internet Information Services的缩写. 微软公司提供的基于运行Microsoft Windows的互联网基本服务. IIS是一种Web（网页）服务组件，其中包括Web服务器、FTP服务器、NNTP服务器和SMTP服务器，分别用于网页浏览、文件传输、新闻服务和邮件发送等方面，它使得在网络（包括互联网和局域网）上发布信息成了一件很容易的事.\n\n## IIS 服务器\n\nIIS服务器是Windows自带的一个服务器, 默认是禁用的, 我们需要在 控制面板 -> 程序与应用 中开启这个服务, 然后在管理工具中添加你的网站即可.\n\n## 配置IIS服务\n\n> 我以 windows 10 为例\n\n找到控制面板, 打开**程序和功能**, 点击左侧的**启用和关闭windows功能**\n\n![ ](/img/iis_01.png)\n\n![ ](/../img/iis_02.png)\n\n如图所示, 勾选 **Internet Information Service** 选项, 会自动帮你选中子选项, 到这里一个简单的iis服务器就算启动了\n\n![ ](/../img/iis_03.png)\n\n> [浏览器输入(或点击这里)](http://localhost)就可以看到以下信息\n\n![ ](/../img/iis_04.png)\n\n## 管理你的网站\n\n### 管理界面\n\n同样的在控制面板, 打开**管理工具**, 找到**Internet Information Service(IIS)管理器**\n\n![ ](/../img/iis_05.png)\n\n这个就是你的IIS服务器的管理界面\n\n### 添加网站\n\n右键**服务器**/**网站**选择**添加网站**, 出现如下界面, 填写网站相关信息即可.\n\n![ ](/../img/iis_06.png)\n\n我将本机的一个图片目录部署为一个网站, *图片服务器*\n\n1. 网站名称, 即你的网站名字.\n2. 应用程序池, 默认即可, 深入的再探讨.\n3. 物理路径, 就是你的项目所在路径\n4. 绑定\n   1. 类型 http/htts, 如果选择为 https 还需要配置证书\n   2. IP地址段, 你可以在你局域网的IP段内自定义, 默认就是本机IP(localhost、127.0.0.1)\n   3. 端口不能重复, 这里我配置为 8001\n5. 主机名,就是你的域名, 默认不需要修改, 相应的修改需要配置 hosts 文件 (路径\"C:\\Windows\\System32\\drivers\\etc\\hosts\")\n\n最后一步, 点击确认保存, 你可以看到:\n\n![ ](/../img/iis_07.png)\n\n打开浏览器,输入 [localhost:8001/1.jpg](http://localhost:8001/1.jpg), 你可以看到:\n\n![ ](/../img/iis_08.png)\n\n## 结语\n\n学无止境","tags":["服务器"]},{"title":"Markdown学习","url":"/shmily-blog/2019/04/26/markdown/","content":"\n这个网站都是所有的文章都是使用 Markdown 编写的,所以我们有必要了解一下 Markdown 的基本语法\n\n## 我们需要了解的\n\n1. Markdown 是什么\n2. 为什么要用 Markdown\n3. 怎么使用 Markdown 基本语法\n4. 总结\n\n### 什么是 Markdown\n\n* Markdown 是一个简单的标记语言,通过**简单的**几个标记使得普通文本文字具有一定的格式,用来写博客再好不过了.\n\n### 为什么要用 Markdown\n\n* **上手快**,语法简单 只需要记住几个符号就能上手了.\n* Markdwon 有着 易读、易写、易更改 等特点\n* Markdwon 最终是被编译成 HTML 代码执行的\n\n### Markdown 的基本语法\n\n#### 标题标签 (#、=、-)\n\n>两种形式:使用 # 符号代表1-6级标题标签, **个数**为级别;  使用 =、- 代表 一、二级标签\n\n```\n# 一级标题<h1>\n## 二级标题 <h2>\n### 三级标题 <h3>\n#### 四级标题 <h4>\n##### 五级标题 <h5>\n```\n\n#### 段落标签 (>)\n\n> 段落(引用)标签 符号与内容之间要有空格, 单个为主,内嵌几层就打几个 **>**    (ps:貌似可以一致打下去)\n>> 内嵌1     >> 内嵌1\n>>> 内嵌2    >>> 内嵌2\n>>>> 内嵌3   >>>> 内嵌3\n\n#### 字体属性\n\n```\n* **字体加粗**  给字体加粗,在字体左右各加两个 *\n* *斜体字*  使文字倾斜,在文字左右各加一个 *\n* ***斜体加粗***  要使文字加粗、倾斜,在文字左右各加三个 *\n* ~~加删除线的文字~~ 左右各 两个 ~\n```\n\n* **字体加粗**  给字体加粗,在字体左右各加两个 *\n* *斜体字*  使文字倾斜,在文字左右各加一个 *\n* ***斜体加粗***  要使文字加粗、倾斜,在文字左右各加三个 *\n* ~~加删除线的文字~~ 左右各 两个 ~\n\n#### 分割线 (-、*)\n\n> 三个(-、*)及三个以上符号即可\n\n效果如下:\n\n```\n---\n***\n* * *\n```\n\n符号(-)分割线\n\n---\n\n符号(*)分割线\n\n******\n\n#### 图片\n\n基本语法\n\n```sh\n![图片语法](https://images.jzwyz.com/blog/tpurl.png \"这是对图片语法的说明图\")\n![图片alt](https://images.jzwyz.com/blog/1.jpg \"图片title\")\n![链接语法](https://images.jzwyz.com/blog/urlsm.png \"链接语法说明\")\n```\n\n效果:\n\n![图片语法](https://images.jzwyz.com/blog/tpurl.png \"这是对图片语法的说明图\")\n\n![图片alt](https://images.jzwyz.com/blog/1.jpg \"图片title\")\n\n![链接语法](https://images.jzwyz.com/blog/urlsm.png \"链接语法说明\")\n\n> 图片alt 显示在图片下方\n> 图片title 就是图片描述,当鼠标移到图片上时显示的内容。title可加可不加 title与url之间以 空格 隔开\n\n#### 链接\n\n与图片语法类似, 开始 不要 ! 符号\n\n```sh\n[百度](https://www.baidu.com \"百度一下\")\n[Github](https://www.github.com \"去Github\")\n```\n\n[百度](https://www.baidu.com \"百度一下\")\n\n[Github](https://www.github.com \"去Github\")\n\n#### 列表\n\n```md\n1. 有序列表\n2. 有序列表\n3. 有序列表\n\n* 无序列表 *\n  + 无序列表 +\n    - 无序列表 -\n  + 无序列白\n* 无序列表\n```\n\n效果:\n\n1. 有序列表\n2. 有序列表\n3. 有序列表\n\n* 无序列表 *\n  + 无序列表 +\n    - 无序列表 -\n  + 无序列白\n* 无序列表\n\n> 列表 分为无序和有序,其语法区别就是 有序列表以**数字.**为符号 序号和内容之间空格分开\n\n> 无序列表 有 (*、+、-) 三个符号, 使用多个时,最顶层应使用 *,次级使用 +,再次级使用 -\n\n> 列表嵌套 下级与上级换行,缩进三个空格\n\n#### 表格\n\n示列 md 代码:\n\n```sh\n列名|列名|列名\n--|:-:|:--—\n内容|内|内容呀\n```\n\n第一行 | 符号分格列名\n\n第二行 - 代码该列中一个字符,一般设置为该列最长字符数量, : 放在 - 哪边就表示 该列字段向:对齐, | 符号分隔列\n  \n再往下,就是每列的数据列\n\n编号|姓名|性别|年龄\n--:|:---:|-:|:--\n01|小明|男|12\n02|小小红|女|15\n\n#### 代码块语法\n\n效果如下:\n\n```sh\n 这是代码块\n```\n\n`这是代码行`\n\n```bash\n# 指定 语言\ndocker run -d --rm -v ~/../workspace/my-blog/source:/app/source --network=app-bridge --name=webblog myblog:1.0\n```\n\n```node\nnode --version\n```\n\n![代码块语法](https://images.jzwyz.com/blog/dmkyf.png \"代码块语法\")","tags":["基础"]},{"title":"Hello World","url":"/shmily-blog/2019/01/01/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\nhexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\nhexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\nhexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\nhexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)","tags":["Hello World"]},{"title":"我的个人博客","url":"/shmily-blog/2018/11/04/我的个人博客/","content":"\n## 这是我的第一个博客\n\n这个博客模版好坑,如果内容过短,在拉到最下面的时候就会自动弹到上面反复的弹\n\n## 这个项目怎么跑\n\n`docker run -d -p 4000:4000 --rm -v ~/myWorkspace/myproject/myblog/source:/app/source --network=app-bridge --name=webblog myblog:1.4`\n\n### 命令说明\n\n* **-d**   docker在后台运行\n* **-p**   指定容器运行的端口映射到机器端口, [内部]:[外部]\n* **--rm** 停止容器即删除\n* **-v**   docker数据卷操作, 将**机器路径**~/myWorkspace/myproject/myblog/source 挂载到**容器路径**/app/source  参考[管理容器中的数据](https://docs.docker-cn.com/engine/tutorials/dockervolumes/)\n* **--network**  docker网络操作, 将容器运行在 app-bridge 桥网络中, 参考[docker容器网络](https://docs.docker-cn.com/engine/userguide/networking/)\n* **--name** 容器的名称\n* **myblog:1.4**  这个是容器的镜像 ***:** 前面是镜像名称,后面是 镜像版本\n\n## 开启搜索功能\n\n```sh\n# npm i hexo-generator-search --save\n```\n\n_config.yml 配置\n\n```yml\nsearch:\n  path: search.json\n  field: post\n```\n\n## 考虑加入admin功能\n\n需要在Dockerfiler添加一下依赖\n`npm install --save hexo-admin-ehc --save --registry=https://registry.npm.taobao.org`\n\n修改_config.xml文件, 当然这是可选的,设置后台密码\n\n```bash\nadmin:\n  username: jason\n  password_hash: $2a$05$XdoQHWQBCutMxgX3iBG0XOfov2LTNelkMDbtMCkaQRgqhoMdV4tAe\n  secret: jason\n```\n\n设置admin基本属性\n\n```bash\nmetadata:\n  author_id: defaultAuthorId\n  language: zh\n```\n\n### 以下为占位符\n\n> 需要注意的是 最后面 myblog:1.0  这个 1.0 代表镜像版本,一情况而定\n","tags":["随便写写"]}]